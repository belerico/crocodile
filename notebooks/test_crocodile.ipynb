{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data onboarded successfully for dataset 'movie_dataset' and table 'movies_table'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    'MovieTitle': ['Batman Begins', 'The Dark Knight', 'Inception'],\n",
    "    'Year': [2005, 2008, 2010],\n",
    "    'Genre': ['Action', 'Action', 'Sci-Fi'],\n",
    "    'Director': ['Christopher Nolan', 'Christopher Nolan', 'Christopher Nolan']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# MongoDB connection\n",
    "client = MongoClient(\"mongodb://mongodb:27017/\")\n",
    "db = client[\"crocodile_db\"]\n",
    "collection = db[\"input_data\"]\n",
    "trace_collection = db[\"processing_trace\"]\n",
    "\n",
    "# Dataset and table names for tracing\n",
    "dataset_name = \"movie_dataset\"\n",
    "table_name = \"movies_table\"\n",
    "\n",
    "# Onboard data\n",
    "for index, row in df.iterrows():\n",
    "    document = {\n",
    "        \"dataset_name\": dataset_name,\n",
    "        \"table_name\": table_name,\n",
    "        \"row_id\": index,\n",
    "        \"data\": row.to_dict(),\n",
    "        \"classified_columns\": {\n",
    "            \"NE\": [\"MovieTitle\"],  # Specify columns to be linked\n",
    "            \"LIT\": [\"Year\", \"Genre\"]  # Specify literal columns\n",
    "        },\n",
    "        \"context_columns\": [\"MovieTitle\", \"Year\", \"Genre\", \"Director\"],  # Specify context columns\n",
    "        \"status\": \"TODO\"\n",
    "    }\n",
    "    collection.insert_one(document)\n",
    "\n",
    "# Initialize the trace collection\n",
    "trace_collection.insert_one({\n",
    "    \"dataset_name\": dataset_name,\n",
    "    \"table_name\": table_name,\n",
    "    \"total_rows\": len(df),\n",
    "    \"processed_rows\": 0,\n",
    "    \"status\": \"PENDING\"  # Initial status before processing\n",
    "})\n",
    "\n",
    "print(f\"Data onboarded successfully for dataset '{dataset_name}' and table '{table_name}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'director', 'release year', 'domestic distributor',\n",
       "       'length in min', 'worldwide gross'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "file_path = './film_input_no_QIDs.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data onboarded successfully for dataset 'imdb_dataset' and table 'film_input_no_QIDs10'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "file_path = './film_input_no_QIDs.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# MongoDB connection\n",
    "client = MongoClient(\"mongodb://mongodb:27017/\")\n",
    "db = client[\"crocodile_db\"]\n",
    "collection = db[\"input_data\"]\n",
    "trace_collection = db[\"processing_trace\"]\n",
    "\n",
    "# Dataset and table names for tracing\n",
    "dataset_name = \"imdb_dataset\"\n",
    "table_name = \"film_input_no_QIDs10\"\n",
    "\n",
    "# Onboard data\n",
    "for index, row in df.iterrows():\n",
    "    document = {\n",
    "        \"dataset_name\": dataset_name,\n",
    "        \"table_name\": table_name,\n",
    "        \"row_id\": index,\n",
    "        \"data\": row.to_dict(),\n",
    "        \"classified_columns\": {\n",
    "            \"NE\": [\"title\", \"director\", \"domestic distributor\"],  # Assuming Series_Title is the column to be linked\n",
    "            \"LIT\": [\"release year\", \"length in min\", \"worldwide gross\"]  # Assuming these are literal columns\n",
    "        },\n",
    "        \"context_columns\": ['title', 'director', 'release year', 'domestic distributor', 'length in min', 'worldwide gross'],  # Context columns\n",
    "        \"status\": \"TODO\"\n",
    "    }\n",
    "    collection.insert_one(document)\n",
    "\n",
    "    #if index == 9:\n",
    "    #    break\n",
    "\n",
    "# Initialize the trace collection\n",
    "trace_collection.insert_one({\n",
    "    \"dataset_name\": dataset_name,\n",
    "    \"table_name\": table_name,\n",
    "    \"total_rows\": len(df),\n",
    "    \"processed_rows\": 0,\n",
    "    \"status\": \"PENDING\"  # Initial status before processing\n",
    "})\n",
    "\n",
    "print(f\"Data onboarded successfully for dataset '{dataset_name}' and table '{table_name}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data onboarded successfully for dataset 'imdb_dataset' and table 'top_1000_movies'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "file_path = './imdb_top_1000.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# MongoDB connection\n",
    "client = MongoClient(\"mongodb://mongodb:27017/\")\n",
    "db = client[\"crocodile_db\"]\n",
    "collection = db[\"input_data\"]\n",
    "trace_collection = db[\"processing_trace\"]\n",
    "\n",
    "# Dataset and table names for tracing\n",
    "dataset_name = \"imdb_dataset\"\n",
    "table_name = \"top_1000_movies\"\n",
    "\n",
    "# Onboard data\n",
    "for index, row in df.iterrows():\n",
    "    document = {\n",
    "        \"dataset_name\": dataset_name,\n",
    "        \"table_name\": table_name,\n",
    "        \"row_id\": index,\n",
    "        \"data\": row.to_dict(),\n",
    "        \"classified_columns\": {\n",
    "            \"NE\": [\"Series_Title\"],  # Assuming Series_Title is the column to be linked\n",
    "            \"LIT\": [\"Released_Year\", \"Genre\"]  # Assuming these are literal columns\n",
    "        },\n",
    "        \"context_columns\": [\"Series_Title\", \"Released_Year\", \"Genre\", \"Director\"],  # Context columns\n",
    "        \"status\": \"TODO\"\n",
    "    }\n",
    "    collection.insert_one(document)\n",
    "\n",
    "    if index == 9:\n",
    "        break\n",
    "\n",
    "# Initialize the trace collection\n",
    "trace_collection.insert_one({\n",
    "    \"dataset_name\": dataset_name,\n",
    "    \"table_name\": table_name,\n",
    "    \"total_rows\": len(df),\n",
    "    \"processed_rows\": 0,\n",
    "    \"status\": \"PENDING\"  # Initial status before processing\n",
    "})\n",
    "\n",
    "print(f\"Data onboarded successfully for dataset '{dataset_name}' and table '{table_name}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity linking process completed.\n"
     ]
    }
   ],
   "source": [
    "from crocodile import Crocodile\n",
    "import os\n",
    "\n",
    "# Create an instance of the Crocodile class\n",
    "crocodile_instance = Crocodile(\n",
    "    mongo_uri=\"mongodb://mongodb:27017/\",\n",
    "    db_name=\"crocodile_db\",\n",
    "    collection_name=\"input_data\",\n",
    "    trace_collection_name=\"processing_trace\",\n",
    "    max_candidates=3,\n",
    "    entity_retrieval_endpoint=os.environ[\"ENTITY_RETRIEVAL_ENDPOINT\"],  # Access the entity retrieval endpoint directly from environment variables\n",
    "    entity_bow_endpoint=os.environ[\"ENTITY_BOW_ENDPOINT\"],  # Access the entity BoW endpoint directly from environment variables\n",
    "    entity_retrieval_token=os.environ[\"ENTITY_RETRIEVAL_TOKEN\"]  # Access the entity retrieval token directly from environment variables\n",
    ")\n",
    "\n",
    "# Run the entity linking process\n",
    "crocodile_instance.run(dataset_name=dataset_name, table_name=table_name)\n",
    "\n",
    "print(\"Entity linking process completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Levenshtein\n",
      "  Downloading levenshtein-0.26.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (3.2 kB)\n",
      "Collecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein)\n",
      "  Downloading rapidfuzz-3.10.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (11 kB)\n",
      "Downloading levenshtein-0.26.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (153 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.9/153.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading rapidfuzz-3.10.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein\n",
      "Successfully installed Levenshtein-0.26.0 rapidfuzz-3.10.0\n"
     ]
    }
   ],
   "source": [
    "! pip install Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crocodile import Crocodile\n",
    "import os\n",
    "# Create an instance of the Crocodile class\n",
    "crocodile_instance = Crocodile(\n",
    "    mongo_uri=\"mongodb://mongodb:27017/\",\n",
    "    db_name=\"crocodile_db\",\n",
    "    collection_name=\"input_data\",\n",
    "    trace_collection_name=\"processing_trace\",\n",
    "    max_candidates=3,\n",
    "    entity_retrieval_endpoint=os.environ[\"ENTITY_RETRIEVAL_ENDPOINT\"],  # Access the entity retrieval endpoint directly from environment variables\n",
    "    entity_bow_endpoint=os.environ[\"ENTITY_BOW_ENDPOINT\"],  # Access the entity BoW endpoint directly from environment variables\n",
    "    entity_retrieval_token=os.environ[\"ENTITY_RETRIEVAL_TOKEN\"\n",
    "    ]  # Access the entity retrieval token directly from environment variables\n",
    ")\n",
    "#crocodile_instance.get_bow_from_api([\"Q90\"])\n",
    "candidates = crocodile_instance.fetch_candidates(\"paris\", \"paris france\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crocodile_instance.get_bow_from_api([\"Q30\", \"Q40\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_text =  \"paris france, Canadian\"\n",
    "description = candidates[0][\"description\"]\n",
    "candidate_tokens = set(crocodile_instance.tokenize_text(description))\n",
    "row_tokens = set(crocodile_instance.tokenize_text(row_text))\n",
    "crocodile_instance.calculate_token_overlap(candidate_tokens, row_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'canadian', 'series', 'television'}, {'canadian', 'france', 'paris'})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_tokens, row_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity Scores between row and candidates:\n",
      "QID: Q100, Similarity: 0.0037\n",
      "QID: Q104123, Similarity: 0.1079\n",
      "QID: Q166262, Similarity: 0.0697\n",
      "QID: Q30, Similarity: 0.0186\n",
      "QID: Q45, Similarity: 0.0000\n",
      "QID: Q5, Similarity: 0.0000\n",
      "QID: Q90, Similarity: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import base64\n",
    "import gzip\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import pickle\n",
    "\n",
    "# Download NLTK resources if not already downloaded\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Global stopwords to avoid reinitializing repeatedly\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to get BoW vectors from the API\n",
    "def get_bow_from_api(qids):\n",
    "    url = 'https://lamapi.hel.sintef.cloud/entity/bow?token=lamapi_demo_2023'\n",
    "    response = requests.post(\n",
    "        url,\n",
    "        headers={'accept': 'application/json', 'Content-Type': 'application/json'},\n",
    "        json={\"json\": qids}\n",
    "    )\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error fetching BoW: {response.status_code}\")\n",
    "        return None\n",
    "    \n",
    "    bow_data = response.json()\n",
    "    \n",
    "    # Decode and decompress the encoded BoW vectors\n",
    "    decoded_vectors = {}\n",
    "    for qid, encoded_data in bow_data.items():\n",
    "        compressed_bytes = base64.b64decode(encoded_data)\n",
    "        decompressed_vector = pickle.loads(gzip.decompress(compressed_bytes))\n",
    "        bow_vector = decompressed_vector\n",
    "        decoded_vectors[qid] = bow_vector\n",
    "    \n",
    "    return decoded_vectors\n",
    "\n",
    "# Function to tokenize text and remove stopwords\n",
    "def tokenize_text(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    return [t for t in tokens if t.isalpha() and t not in stop_words]\n",
    "\n",
    "# Function to build a row vector (BoW)\n",
    "def build_row_vector(row_text, shared_vocab):\n",
    "    row_tokens = tokenize_text(row_text)\n",
    "    row_bow = Counter(row_tokens)\n",
    "    \n",
    "    # Create a vector for the row based on the shared vocabulary\n",
    "    row_bow_vector = np.array([row_bow.get(word, 0) for word in shared_vocab])\n",
    "    \n",
    "    return row_bow_vector\n",
    "\n",
    "# Function to compute cosine similarity between row and candidate vectors\n",
    "def compute_similarity(row_bow_vector, candidate_vectors, shared_vocab):\n",
    "    similarities = {}\n",
    "    for qid, candidate_bow in candidate_vectors.items():\n",
    "        candidate_bow_vector = np.array([candidate_bow.get(word, 0) for word in shared_vocab])\n",
    "        similarity = cosine_similarity([row_bow_vector], [candidate_bow_vector])[0][0]\n",
    "        similarities[qid] = similarity\n",
    "    return similarities\n",
    "\n",
    "# Test case: simulate a row of data (e.g., a table row)\n",
    "row = {\n",
    "    'city': 'Paris',\n",
    "    'country': 'France',\n",
    "    'continent': 'Europe',\n",
    "    'population': '2140526',\n",
    "    'area_km2': '105.4',\n",
    "    'language': 'French'\n",
    "}\n",
    "\n",
    "row = {\n",
    "    'Series_Title': 'Pulp Fiction',\n",
    "    'Released_Year': 1994,\n",
    "    'Runtime (min)': 154,\n",
    "    'Genre': 'Crime, Drama',\n",
    "    'IMDB_Rating': 8.9,\n",
    "    'Overview': 'The lives of two mob hitmen, a boxer, a gangster and his wife, and a pair of diner bandits intertwine in four tales of violence and redemption.',\n",
    "    'Meta_score': 94.0,\n",
    "    'Director': 'Quentin Tarantino',\n",
    "    'Star1': 'John Travolta',\n",
    "    'No_of_Votes': 1826188,\n",
    "    'Gross': '107,928,762'\n",
    "}\n",
    "\n",
    "# Combine the row data into a single text string for BoW processing\n",
    "row_text = ' '.join([str(row[index]) for index in row if index != 'Overview'])\n",
    "\n",
    "# Step 1: Retrieve BoW vectors from API for some QIDs\n",
    "qids = [\"Q30\", \"Q166262\", \"Q90\", \"Q104123\", \"Q45\", \"Q100\", \"Q5\"]  # Example QIDs\n",
    "candidate_vectors = get_bow_from_api(qids)\n",
    "\n",
    "if candidate_vectors is None:\n",
    "    print(\"No candidate vectors retrieved from the API.\")\n",
    "else:\n",
    "    # Step 2: Ensure consistent shared vocabulary\n",
    "    shared_vocab = set()\n",
    "    for vector in candidate_vectors.values():\n",
    "        shared_vocab.update(vector.keys())  # Collect vocabulary from candidate BoWs\n",
    "    row_tokens = tokenize_text(row_text)\n",
    "    shared_vocab.update(row_tokens)\n",
    "    shared_vocab = list(shared_vocab)\n",
    "\n",
    "    # Step 3: Build the row vector (BoW)\n",
    "    row_bow_vector = build_row_vector(row_text, shared_vocab)\n",
    "\n",
    "    # Step 4: Compute similarity between row and candidate vectors\n",
    "    similarity_scores = compute_similarity(row_bow_vector, candidate_vectors, shared_vocab)\n",
    "\n",
    "    # Step 5: Output the similarity scores\n",
    "    print(\"\\nSimilarity Scores between row and candidates:\")\n",
    "    for qid, score in similarity_scores.items():\n",
    "        print(f\"QID: {qid}, Similarity: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pulp',\n",
       " 'fiction',\n",
       " 'crime',\n",
       " 'drama',\n",
       " 'lives',\n",
       " 'two',\n",
       " 'mob',\n",
       " 'hitmen',\n",
       " 'boxer',\n",
       " 'gangster',\n",
       " 'wife',\n",
       " 'pair',\n",
       " 'diner',\n",
       " 'bandits',\n",
       " 'intertwine',\n",
       " 'four',\n",
       " 'tales',\n",
       " 'violence',\n",
       " 'redemption',\n",
       " 'quentin',\n",
       " 'tarantino',\n",
       " 'john',\n",
       " 'travolta']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "file_path = './imdb_top_1000.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# MongoDB connection\n",
    "client = MongoClient(\"mongodb://mongodb:27017/\")\n",
    "db = client[\"crocodile_db\"]\n",
    "collection = db[\"input_data\"]\n",
    "trace_collection = db[\"processing_trace\"]\n",
    "results = collection.find({})\n",
    "outcome = []\n",
    "for result in results:\n",
    "    outcome.append((result[\"row_id\"], result[\"el_results\"][\"title\"][0][\"id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>Title_QID</th>\n",
       "      <th>director</th>\n",
       "      <th>release year</th>\n",
       "      <th>domestic distributor</th>\n",
       "      <th>length in min</th>\n",
       "      <th>worldwide gross</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jurassic World</td>\n",
       "      <td>Q3512046</td>\n",
       "      <td>Colin Trevorrow</td>\n",
       "      <td>2015</td>\n",
       "      <td>Universal Pictures</td>\n",
       "      <td>124</td>\n",
       "      <td>1670400637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Superman Returns</td>\n",
       "      <td>Q328695</td>\n",
       "      <td>Bryan Singer</td>\n",
       "      <td>2006</td>\n",
       "      <td>Warner Bros.</td>\n",
       "      <td>154</td>\n",
       "      <td>391081192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Batman Begins</td>\n",
       "      <td>Q166262</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>2005</td>\n",
       "      <td>Warner Bros.</td>\n",
       "      <td>140</td>\n",
       "      <td>371853783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Avatar</td>\n",
       "      <td>Q24871</td>\n",
       "      <td>James Cameron</td>\n",
       "      <td>2009</td>\n",
       "      <td>20th Century Fox</td>\n",
       "      <td>162</td>\n",
       "      <td>2744336793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Titanic</td>\n",
       "      <td>Q44578</td>\n",
       "      <td>James Cameron</td>\n",
       "      <td>1997</td>\n",
       "      <td>Paramount Pictures</td>\n",
       "      <td>194</td>\n",
       "      <td>2208208395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Avengers</td>\n",
       "      <td>Q182218</td>\n",
       "      <td>Joss Whedon</td>\n",
       "      <td>2012</td>\n",
       "      <td>Disney</td>\n",
       "      <td>143</td>\n",
       "      <td>1518815515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Harry Potter and the Deathly Hallows Part 2</td>\n",
       "      <td>Q232009</td>\n",
       "      <td>David Yates</td>\n",
       "      <td>2011</td>\n",
       "      <td>Warner Bros.</td>\n",
       "      <td>130</td>\n",
       "      <td>1341511219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Furious 7</td>\n",
       "      <td>Q14650496</td>\n",
       "      <td>James Wan</td>\n",
       "      <td>2015</td>\n",
       "      <td>Universal Pictures</td>\n",
       "      <td>137</td>\n",
       "      <td>1515047671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Frozen</td>\n",
       "      <td>Q246283</td>\n",
       "      <td>Chris Buck and Jennifer Lee</td>\n",
       "      <td>2013</td>\n",
       "      <td>Walt Disney Pictures</td>\n",
       "      <td>102</td>\n",
       "      <td>1281983879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Iron Man 3</td>\n",
       "      <td>Q209538</td>\n",
       "      <td>Shane Black</td>\n",
       "      <td>2013</td>\n",
       "      <td>Disney</td>\n",
       "      <td>130</td>\n",
       "      <td>1215439994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Transformers: Dark of the Moon</td>\n",
       "      <td>Q232774</td>\n",
       "      <td>Michael Bay</td>\n",
       "      <td>2011</td>\n",
       "      <td>Paramount Pictures</td>\n",
       "      <td>157</td>\n",
       "      <td>1123746996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The Lord of the Rings: The Return of the King</td>\n",
       "      <td>Q131074</td>\n",
       "      <td>Peter Jackson</td>\n",
       "      <td>2003</td>\n",
       "      <td>New Line Cinema</td>\n",
       "      <td>201</td>\n",
       "      <td>1146030912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Pirates of the Caribbean: Dead Man's Chest</td>\n",
       "      <td>Q161087</td>\n",
       "      <td>Gore Verbinski</td>\n",
       "      <td>2006</td>\n",
       "      <td>Walt Disney Pictures</td>\n",
       "      <td>150</td>\n",
       "      <td>1065659812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>Q163872</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>2008</td>\n",
       "      <td>Warner Bros.</td>\n",
       "      <td>152</td>\n",
       "      <td>1004558444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Transformers</td>\n",
       "      <td>Q171453</td>\n",
       "      <td>Michael Bay</td>\n",
       "      <td>2007</td>\n",
       "      <td>Paramount Pictures</td>\n",
       "      <td>144</td>\n",
       "      <td>709709780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>Q54274</td>\n",
       "      <td>Gore Verbinski</td>\n",
       "      <td>2007</td>\n",
       "      <td>Walt Disney Pictures</td>\n",
       "      <td>169</td>\n",
       "      <td>963420425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Skyfall</td>\n",
       "      <td>Q4941</td>\n",
       "      <td>Sam Mendes</td>\n",
       "      <td>2012</td>\n",
       "      <td>Columbia Pictures</td>\n",
       "      <td>143</td>\n",
       "      <td>1108561013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>The Hobbit: An Unexpected Journey</td>\n",
       "      <td>Q80379</td>\n",
       "      <td>Peter Jackson</td>\n",
       "      <td>2012</td>\n",
       "      <td>Warner Bros.</td>\n",
       "      <td>169</td>\n",
       "      <td>1021103568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>The Lion King</td>\n",
       "      <td>Q27044293</td>\n",
       "      <td>Jon Favreau</td>\n",
       "      <td>2019</td>\n",
       "      <td>Disney</td>\n",
       "      <td>118</td>\n",
       "      <td>1656916569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>The Incredibles</td>\n",
       "      <td>Q213326</td>\n",
       "      <td>Brad Bird</td>\n",
       "      <td>2004</td>\n",
       "      <td>Disney</td>\n",
       "      <td>115</td>\n",
       "      <td>633019734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>Q212965</td>\n",
       "      <td>Gary Ross</td>\n",
       "      <td>2012</td>\n",
       "      <td>Lionsgate</td>\n",
       "      <td>142</td>\n",
       "      <td>694394724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Spider-Man</td>\n",
       "      <td>Q484442</td>\n",
       "      <td>Sam Raimi</td>\n",
       "      <td>2002</td>\n",
       "      <td>Sony Pictures</td>\n",
       "      <td>121</td>\n",
       "      <td>821708551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>The Matrix Reloaded</td>\n",
       "      <td>Q189600</td>\n",
       "      <td>Lana Wachowski and Lilly Wachowski</td>\n",
       "      <td>2003</td>\n",
       "      <td>Warner Bros.</td>\n",
       "      <td>138</td>\n",
       "      <td>739398464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>The Twilight Saga: Eclipse</td>\n",
       "      <td>Q217010</td>\n",
       "      <td>David Slade</td>\n",
       "      <td>2010</td>\n",
       "      <td>Summit Entertainment</td>\n",
       "      <td>124</td>\n",
       "      <td>698491347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Deadpool</td>\n",
       "      <td>Q19347291</td>\n",
       "      <td>Tim Miller</td>\n",
       "      <td>2016</td>\n",
       "      <td>20th Century Fox</td>\n",
       "      <td>108</td>\n",
       "      <td>783112979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>When Father Was Away on Business</td>\n",
       "      <td>Q433000</td>\n",
       "      <td>Emir Kusturica</td>\n",
       "      <td>1985</td>\n",
       "      <td>Centar film</td>\n",
       "      <td>136</td>\n",
       "      <td>41184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Fall</td>\n",
       "      <td>Q113470320</td>\n",
       "      <td>Scott Mann</td>\n",
       "      <td>2022</td>\n",
       "      <td>BuzzFeed</td>\n",
       "      <td>107</td>\n",
       "      <td>13700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Army of Darkness</td>\n",
       "      <td>Q471992</td>\n",
       "      <td>Sam Raimi</td>\n",
       "      <td>1992</td>\n",
       "      <td>Raimi Pictures</td>\n",
       "      <td>81</td>\n",
       "      <td>11502976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Beyond the Edge</td>\n",
       "      <td>Q28667926</td>\n",
       "      <td>Aleksandr Boguslavskiy</td>\n",
       "      <td>2017</td>\n",
       "      <td>KD Studios</td>\n",
       "      <td>102</td>\n",
       "      <td>2040470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Venom: Let There Be Carnage</td>\n",
       "      <td>Q60498064</td>\n",
       "      <td>Andy Serkis</td>\n",
       "      <td>2021</td>\n",
       "      <td>Columbia Pictures</td>\n",
       "      <td>120</td>\n",
       "      <td>13076089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            title   Title_QID  \\\n",
       "0                                  Jurassic World    Q3512046   \n",
       "1                                Superman Returns     Q328695   \n",
       "2                                   Batman Begins     Q166262   \n",
       "3                                          Avatar      Q24871   \n",
       "4                                         Titanic      Q44578   \n",
       "5                                    The Avengers     Q182218   \n",
       "6     Harry Potter and the Deathly Hallows Part 2     Q232009   \n",
       "7                                       Furious 7   Q14650496   \n",
       "8                                          Frozen     Q246283   \n",
       "9                                      Iron Man 3     Q209538   \n",
       "10                 Transformers: Dark of the Moon     Q232774   \n",
       "11  The Lord of the Rings: The Return of the King     Q131074   \n",
       "12     Pirates of the Caribbean: Dead Man's Chest     Q161087   \n",
       "13                                The Dark Knight     Q163872   \n",
       "14                                   Transformers     Q171453   \n",
       "15       Pirates of the Caribbean: At World's End      Q54274   \n",
       "16                                        Skyfall       Q4941   \n",
       "17              The Hobbit: An Unexpected Journey      Q80379   \n",
       "18                                  The Lion King   Q27044293   \n",
       "19                                The Incredibles     Q213326   \n",
       "20                               The Hunger Games     Q212965   \n",
       "21                                     Spider-Man     Q484442   \n",
       "22                            The Matrix Reloaded     Q189600   \n",
       "23                     The Twilight Saga: Eclipse     Q217010   \n",
       "24                                       Deadpool   Q19347291   \n",
       "25               When Father Was Away on Business     Q433000   \n",
       "26                                           Fall  Q113470320   \n",
       "27                               Army of Darkness     Q471992   \n",
       "28                                Beyond the Edge   Q28667926   \n",
       "29                    Venom: Let There Be Carnage   Q60498064   \n",
       "\n",
       "                              director  release year  domestic distributor  \\\n",
       "0                      Colin Trevorrow          2015    Universal Pictures   \n",
       "1                         Bryan Singer          2006          Warner Bros.   \n",
       "2                    Christopher Nolan          2005          Warner Bros.   \n",
       "3                        James Cameron          2009      20th Century Fox   \n",
       "4                        James Cameron          1997    Paramount Pictures   \n",
       "5                          Joss Whedon          2012                Disney   \n",
       "6                          David Yates          2011          Warner Bros.   \n",
       "7                            James Wan          2015    Universal Pictures   \n",
       "8          Chris Buck and Jennifer Lee          2013  Walt Disney Pictures   \n",
       "9                          Shane Black          2013                Disney   \n",
       "10                         Michael Bay          2011    Paramount Pictures   \n",
       "11                       Peter Jackson          2003       New Line Cinema   \n",
       "12                      Gore Verbinski          2006  Walt Disney Pictures   \n",
       "13                   Christopher Nolan          2008          Warner Bros.   \n",
       "14                         Michael Bay          2007    Paramount Pictures   \n",
       "15                      Gore Verbinski          2007  Walt Disney Pictures   \n",
       "16                          Sam Mendes          2012     Columbia Pictures   \n",
       "17                       Peter Jackson          2012          Warner Bros.   \n",
       "18                         Jon Favreau          2019                Disney   \n",
       "19                           Brad Bird          2004                Disney   \n",
       "20                           Gary Ross          2012             Lionsgate   \n",
       "21                           Sam Raimi          2002         Sony Pictures   \n",
       "22  Lana Wachowski and Lilly Wachowski          2003          Warner Bros.   \n",
       "23                         David Slade          2010  Summit Entertainment   \n",
       "24                          Tim Miller          2016      20th Century Fox   \n",
       "25                      Emir Kusturica          1985           Centar film   \n",
       "26                          Scott Mann          2022              BuzzFeed   \n",
       "27                           Sam Raimi          1992        Raimi Pictures   \n",
       "28              Aleksandr Boguslavskiy          2017            KD Studios   \n",
       "29                         Andy Serkis          2021     Columbia Pictures   \n",
       "\n",
       "    length in min  worldwide gross  \n",
       "0             124       1670400637  \n",
       "1             154        391081192  \n",
       "2             140        371853783  \n",
       "3             162       2744336793  \n",
       "4             194       2208208395  \n",
       "5             143       1518815515  \n",
       "6             130       1341511219  \n",
       "7             137       1515047671  \n",
       "8             102       1281983879  \n",
       "9             130       1215439994  \n",
       "10            157       1123746996  \n",
       "11            201       1146030912  \n",
       "12            150       1065659812  \n",
       "13            152       1004558444  \n",
       "14            144        709709780  \n",
       "15            169        963420425  \n",
       "16            143       1108561013  \n",
       "17            169       1021103568  \n",
       "18            118       1656916569  \n",
       "19            115        633019734  \n",
       "20            142        694394724  \n",
       "21            121        821708551  \n",
       "22            138        739398464  \n",
       "23            124        698491347  \n",
       "24            108        783112979  \n",
       "25            136            41184  \n",
       "26            107         13700000  \n",
       "27             81         11502976  \n",
       "28            102          2040470  \n",
       "29            120         13076089  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"film_with_QIDs.csv\") \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame(outcome)\n",
    "sum(df2[1] == df[\"Title_QID\"]) / len(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data onboarded successfully for dataset 'test' and table '0DO2KMKV'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "file_path = './0DO2KMKV.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# MongoDB connection\n",
    "client = MongoClient(\"mongodb://mongodb:27017/\")\n",
    "db = client[\"crocodile_db\"]\n",
    "collection = db[\"input_data\"]\n",
    "trace_collection = db[\"processing_trace\"]\n",
    "\n",
    "# Dataset and table names for tracing\n",
    "dataset_name = \"test\"\n",
    "table_name = \"0DO2KMKV\"\n",
    "\n",
    "# Onboard data\n",
    "for index, row in df.iterrows():\n",
    "    document = {\n",
    "        \"dataset_name\": dataset_name,\n",
    "        \"table_name\": table_name,\n",
    "        \"row_id\": index,\n",
    "        \"data\": row.to_dict(),\n",
    "        \"classified_columns\": {\n",
    "            \"NE\": [\"col0\"],  # Assuming Series_Title is the column to be linked\n",
    "            \"LIT\": [\"col1\"]  # Assuming these are literal columns\n",
    "        },\n",
    "        \"context_columns\": list(df.columns),  # Context columns\n",
    "        \"status\": \"TODO\"\n",
    "    }\n",
    "    collection.insert_one(document)\n",
    "\n",
    "    #if index == 9:\n",
    "    #    break\n",
    "\n",
    "# Initialize the trace collection\n",
    "trace_collection.insert_one({\n",
    "    \"dataset_name\": dataset_name,\n",
    "    \"table_name\": table_name,\n",
    "    \"total_rows\": len(df),\n",
    "    \"processed_rows\": 0,\n",
    "    \"status\": \"PENDING\"  # Initial status before processing\n",
    "})\n",
    "\n",
    "print(f\"Data onboarded successfully for dataset '{dataset_name}' and table '{table_name}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity linking process completed.\n"
     ]
    }
   ],
   "source": [
    "from crocodile import Crocodile\n",
    "import os\n",
    "\n",
    "# Create an instance of the Crocodile class\n",
    "crocodile_instance = Crocodile(\n",
    "    mongo_uri=\"mongodb://mongodb:27017/\",\n",
    "    db_name=\"crocodile_db\",\n",
    "    collection_name=\"input_data\",\n",
    "    trace_collection_name=\"processing_trace\",\n",
    "    max_candidates=3,\n",
    "    entity_retrieval_endpoint=os.environ[\"ENTITY_RETRIEVAL_ENDPOINT\"],  # Access the entity retrieval endpoint directly from environment variables\n",
    "    entity_bow_endpoint=os.environ[\"ENTITY_BOW_ENDPOINT\"],  # Access the entity BoW endpoint directly from environment variables\n",
    "    entity_retrieval_token=os.environ[\"ENTITY_RETRIEVAL_TOKEN\"]  # Access the entity retrieval token directly from environment variables\n",
    ")\n",
    "\n",
    "# Run the entity linking process\n",
    "crocodile_instance.run(dataset_name=dataset_name, table_name=table_name)\n",
    "\n",
    "print(\"Entity linking process completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data onboarded successfully for dataset 'test' and table 'VGUZX5R3'.\n",
      "{'col0': 'Equatorial Guinea', 'col1': 'Malabooo', 'col2': '187,302', 'col3': 'Bata', 'col4': '250,770', 'col5': 1.34}{'col0': 'Burundii', 'col1': 'Gitegaa', 'col2': '22,989', 'col3': 'Bujumbura', 'col4': '497,166', 'col5': 21.6}{'col0': 'Australiaa', 'col1': 'Canberrraa', 'col2': '390,706', 'col3': 'Sydney', 'col4': '4,921,000', 'col5': 12.6}{'col0': 'Bollivia', 'col1': 'Sucreee', 'col2': '259,388', 'col3': 'Santa Cruz de la Sierra', 'col4': '1,453,549', 'col5': 7.1}  {'0': 'LOCATION', '1': 'LOCATION', '3': 'LOCATION'} {'col0': 'Benin', 'col1': 'Porto-Novooo', 'col2': '223,500', 'col3': 'Cotonou', 'col4': '761,100', 'col5': 3.4} {'col0': 'Indiaa', 'col1': 'NNew Delhi', 'col2': '249,998', 'col3': 'Mumbai', 'col4': '12,442,373', 'col5': 49.77}{'col0': 'Belize', 'col1': 'Belmopannn', 'col2': '16,400', 'col3': 'Belize City', 'col4': '70,000', 'col5': 4.27}\n",
      "{'0': 'LOCATION', '1': 'LOCATION', '3': 'LOCATION'}{'0': 'LOCATION', '1': 'LOCATION', '3': 'LOCATION'}{'col0': 'Canada', 'col1': 'Ottawaa', 'col2': '812,129', 'col3': 'Toronto', 'col4': '2,503,281', 'col5': 3.08} {'col0': 'Braziil', 'col1': 'Brasíliaa', 'col2': '2,557,158', 'col3': 'São Paulo', 'col4': '11,150,249', 'col5': 4.55}{'0': 'LOCATION', '1': 'LOCATION', '3': 'LOCATION'} \n",
      "  \n",
      " {'col0': 'China', 'col1': 'Beijingg', 'col2': '22,000,000', 'col3': 'Shanghai', 'col4': '34,000,000', 'col5': 1.55}\n",
      "{'0': 'LOCATION', '1': 'LOCATION', '3': 'LOCATION'}{'0': 'LOCATION', '1': 'LOCATION', '3': 'LOCATION'}{'0': 'LOCATION', '1': 'LOCATION', '3': 'LOCATION'}{'0': 'LOCATION', '1': 'LOCATION', '3': 'LOCATION'}{'0': 'LOCATION', '1': 'LOCATION', '3': 'LOCATION'}\n",
      "{'col0': \"Côte d'Ivoire\", 'col1': 'Yamoussoukroo', 'col2': '200,659', 'col3': 'Abidjan', 'col4': '4,348,000', 'col5': 21.7} \n",
      "\n",
      " \n",
      "{'col0': 'Cameroon', 'col1': 'Yaoundééé', 'col2': '1,430,000', 'col3': 'Douala', 'col4': '2,000,000 +', 'col5': 1.4}\n",
      "{'0': 'LOCATION', '1': 'LOCATION', '3': 'LOCATION'}\n",
      "{'0': 'LOCATION', '1': 'LOCATION', '3': 'LOCATION'} \n",
      "{'0': 'LOCATION', '1': 'LOCATION', '3': 'LOCATION'}\n",
      "{'col0': 'Moroccoo', 'col1': 'Rabatt', 'col2': '627,000', 'col3': 'Casablanca', 'col4': '4,150,000', 'col5': 6.62}{'col0': 'Myyanmar', 'col1': 'NNaypyidaw', 'col2': '925,000', 'col3': 'Yangon', 'col4': '4,346,000', 'col5': 4.7}{'col0': 'Liechtensteinn', 'col1': 'Vaduuzz', 'col2': '5,109', 'col3': 'Schaan', 'col4': '5,806', 'col5': 1.14}{'col0': 'Federated States of Micronesiaa', 'col1': 'Palikirr', 'col2': '5,000', 'col3': 'Weno', 'col4': '13,000', 'col5': 2.6}{'col0': 'Kazakhstan', 'col1': 'Nur-Sultann', 'col2': '743,014', 'col3': 'Almaty', 'col4': '1,450,095', 'col5': 1.95}{'col0': 'Malta', 'col1': 'Vallletta', 'col2': '6,000', 'col3': 'Birkirkara', 'col4': '21,000', 'col5': 3.5} {'col0': 'New Zealandd', 'col1': 'Wellingtonn', 'col2': '418,500', 'col3': 'Auckland', 'col4': '1,570,100', 'col5': 3.75}{'col0': 'Nigeriia', 'col1': 'Abuujaa', 'col2': '778,567', 'col3': 'Lagos', 'col4': '7,937,932', 'col5': 10.2}{'col0': 'Pakistann', 'col1': 'Islamabadd', 'col2': '1,740,000', 'col3': 'Karachi', 'col4': '24,300,000', 'col5': 13.97}   {'col0': 'PPalau', 'col1': 'Ngerulmud', 'col2': '271', 'col3': 'Koror', 'col4': '11,200', 'col5': 41.32}{'col0': 'San Marino', 'col1': 'San Marinooo', 'col2': '4,211', 'col3': 'Serravalle', 'col4': '10,601', 'col5': 2.52} {'0': 'LOCATION', '1': 'LOCATION', '3': 'LOCATION'}{'0': 'LOCATION', '1': 'LOCATION', '3': 'LOCATION'}  {'col0': 'Philippiness', 'col1': 'Manilaa', 'col2': '1,780,148', 'col3': 'Quezon City', 'col4': '2,936,116', 'col5': 1.67}   {'0': 'LOCATION', '1': 'LOCATION', '3': 'LOCATION'}{'0': 'LOCATION', '1': 'LOCATION', '3': 'LOCATION'} {'0': 'LOCATION', '1': 'LOCATION', '3': 'LOCATION'}{'0': 'LOCATION', '1': 'LOCATION', '3': 'LOCATION'}\n",
      "{'0': 'LOCATION', '1': 'LOCATION', '3': 'LOCATION'} \n",
      "{'0': 'LOCATION', '1': 'LOCATION', '3': 'LOCATION'}\n",
      "{'0': 'LOCATION', '1': 'LOCATION', '3': 'LOCATION'}{'0': 'LOCATION', '1': 'LOCATION', '3': 'LOCATION'}\n",
      "{'0': 'LOCATION', '1': 'LOCATION', '3': 'LOCATION'}\n",
      "{'0': 'LOCATION', '1': 'LOCATION', '3': 'LOCATION'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{'col0': 'South Africa', 'col1': 'Pretoriaa', 'col2': '2,345,908', 'col3': 'Johannesburg', 'col4': '3,888,180', 'col5': 1.66}{'col0': 'Trinidad and Tobagoo', 'col1': 'Port of Spainn', 'col2': '49,000', 'col3': 'Chaguanas', 'col4': '67,400', 'col5': 1.37}{'col0': 'Switzerlandd', 'col1': 'Bernnn', 'col2': '138,041', 'col3': 'Zürich', 'col4': '397,698', 'col5': 2.88}{'col0': 'SSri Lanka', 'col1': 'Sri Jayawardenepura Kottee', 'col2': '115,826', 'col3': 'Colombo', 'col4': '642,163', 'col5': 5.54}{'col0': 'Tanzaniaa', 'col1': 'Dodomaaa', 'col2': '324,347', 'col3': 'Dar es Salaam', 'col4': '2,497,940', 'col5': 7.7}{'col0': 'United Arab Emirates', 'col1': 'Abu Dhhhabi', 'col2': '896,751', 'col3': 'Dubai', 'col4': '2,262,000', 'col5': 2.52}{'col0': 'Sudaan', 'col1': 'Khartoummm', 'col2': '2,207,794', 'col3': 'Omdurman', 'col4': '2,395,159', 'col5': 1.08}{'col0': 'Vietnamm', 'col1': 'Hanoii', 'col2': '6,500,000', 'col3': 'Ho Chi Minh City', 'col4': '7,123,340', 'col5': 1.1}{'col0': 'United States', 'col1': 'Washington, D.C..', 'col2': '672,228', 'col3': 'New York City', 'col4': '8,550,405', 'col5': 12.72} {'col0': 'Turkey', 'col1': 'Ankaraa', 'col2': '5,150,072', 'col3': 'Istanbul', 'col4': '14,377,018', 'col5': 3.4}         {'0': 'LOCATION', '1': 'LOCATION', '3': 'LOCATION'}{'0': 'LOCATION', '1': 'LOCATION', '3': 'LOCATION'}{'0': 'LOCATION', '1': 'LOCATION', '3': 'LOCATION'}{'0': 'LOCATION', '1': 'LOCATION', '3': 'LOCATION'}{'0': 'LOCATION', '1': 'LOCATION', '3': 'LOCATION'}{'0': 'LOCATION', '1': 'LOCATION', '3': 'LOCATION'}{'0': 'LOCATION', '1': 'LOCATION', '3': 'LOCATION'}\n",
      "\n",
      "{'0': 'LOCATION', '1': 'LOCATION', '3': 'LOCATION'}\n",
      "\n",
      "{'0': 'LOCATION', '1': 'LOCATION', '3': 'LOCATION'}\n",
      "\n",
      "\n",
      "\n",
      "{'0': 'LOCATION', '1': 'LOCATION', '3': 'LOCATION'}\n",
      "\n",
      "Entity linking process completed.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "from crocodile import Crocodile\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "file_path = './tables/VGUZX5R3.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# MongoDB connection\n",
    "client = MongoClient(\"mongodb://mongodb:27017/\")\n",
    "db = client[\"crocodile_db\"]\n",
    "collection = db[\"input_data\"]\n",
    "trace_collection = db[\"processing_trace\"]\n",
    "\n",
    "# Dataset and table names for tracing\n",
    "dataset_name = \"test\"\n",
    "table_name = \"VGUZX5R3\"\n",
    "\n",
    "# Load the correct QIDs for the table\n",
    "with open('./tables/correct_qids_VGUZX5R3.json', 'r') as file:\n",
    "    correct_qids = json.load(file)\n",
    "\n",
    "\n",
    "# Onboard data\n",
    "for index, row in df.iterrows():\n",
    "    document = {\n",
    "        \"dataset_name\": dataset_name,\n",
    "        \"table_name\": table_name,\n",
    "        \"row_id\": index,\n",
    "        \"data\": row.to_dict(),\n",
    "        \"classified_columns\": {\n",
    "            \"NE\": {\n",
    "                \"0\": \"LOCATION\",\n",
    "                \"1\": \"LOCATION\",\n",
    "                \"3\": \"LOCATION\"\n",
    "            },\n",
    "            \"LIT\": [\"2\", \"4\", \"5\"]\n",
    "        },\n",
    "        \"context_columns\": [str(i) for i in range(len(list(df.columns)))],  # Context columns\n",
    "        \"correct_qids\": correct_qids,\n",
    "        \"status\": \"TODO\"\n",
    "    }\n",
    "    collection.insert_one(document)\n",
    "\n",
    "\n",
    "# Initialize the trace collection\n",
    "trace_collection.insert_one({\n",
    "    \"dataset_name\": dataset_name,\n",
    "    \"table_name\": table_name,\n",
    "    \"total_rows\": len(df),\n",
    "    \"processed_rows\": 0,\n",
    "    \"status\": \"PENDING\"  # Initial status before processing\n",
    "})\n",
    "\n",
    "print(f\"Data onboarded successfully for dataset '{dataset_name}' and table '{table_name}'.\")\n",
    "\n",
    "\n",
    "# Create an instance of the Crocodile class\n",
    "crocodile_instance = Crocodile(\n",
    "    mongo_uri=\"mongodb://mongodb:27017/\",\n",
    "    db_name=\"crocodile_db\",\n",
    "    collection_name=\"input_data\",\n",
    "    trace_collection_name=\"processing_trace\",\n",
    "    max_candidates=3,\n",
    "    entity_retrieval_endpoint=os.environ[\"ENTITY_RETRIEVAL_ENDPOINT\"],  # Access the entity retrieval endpoint directly from environment variables\n",
    "    entity_bow_endpoint=os.environ[\"ENTITY_BOW_ENDPOINT\"],  # Access the entity BoW endpoint directly from environment variables\n",
    "    entity_retrieval_token=os.environ[\"ENTITY_RETRIEVAL_TOKEN\"]  # Access the entity retrieval token directly from environment variables\n",
    ")\n",
    "\n",
    "# Run the entity linking process\n",
    "crocodile_instance.run(dataset_name=dataset_name, table_name=table_name)\n",
    "\n",
    "print(\"Entity linking process completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['player', 'position', 'country', 'birthplace', 'played', 'teams ↓',\n",
       "       'notes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "file_path = './tables/VGUZX5R3.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Dataset and table names for tracing\n",
    "dataset_name = \"test\"\n",
    "table_name = \"VGUZX5R3\"\n",
    "\n",
    "# Load the correct QIDs for the table\n",
    "with open('./tables/correct_qids_VGUZX5R3.json', 'r') as file:\n",
    "    correct_qids = json.load(file)\n",
    "\n",
    "# Onboard data\n",
    "for index, row in df.iterrows():\n",
    "    document = {\n",
    "        \"dataset_name\": dataset_name,\n",
    "        \"table_name\": table_name,\n",
    "        \"row_id\": index,\n",
    "        \"data\": row.to_dict(),\n",
    "        \"classified_columns\": {\n",
    "            \"NE\": {\n",
    "                \"col0\": \"LOCATION\",\n",
    "                \"col1\": \"LOCATION\",\n",
    "                \"col3\": \"LOCATION\"\n",
    "            },\n",
    "            \"LIT\": [\"col2\", \"col4\", \"col5\"]\n",
    "        },\n",
    "        \"context_columns\": [i for i in range(len(list(df.columns)))],  # Context columns\n",
    "        \"correct_qids\": correct_qids,\n",
    "        \"status\": \"TODO\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_name': 'test',\n",
       " 'table_name': 'VGUZX5R3',\n",
       " 'row_id': 33,\n",
       " 'data': {'col0': 'Vietnamm',\n",
       "  'col1': 'Hanoii',\n",
       "  'col2': '6,500,000',\n",
       "  'col3': 'Ho Chi Minh City',\n",
       "  'col4': '7,123,340',\n",
       "  'col5': 1.1},\n",
       " 'classified_columns': {'NE': {'col0': 'LOCATION',\n",
       "   'col1': 'LOCATION',\n",
       "   'col3': 'LOCATION'},\n",
       "  'LIT': ['col2', 'col4', 'col5']},\n",
       " 'context_columns': [0, 1, 2, 3, 4, 5],\n",
       " 'correct_qids': {'0-0': 'Q408',\n",
       "  '0-1': 'Q3114',\n",
       "  '0-3': 'Q3130',\n",
       "  '1-0': 'Q242',\n",
       "  '1-1': 'Q3043',\n",
       "  '1-3': 'Q108223',\n",
       "  '2-0': 'Q962',\n",
       "  '2-1': 'Q3799',\n",
       "  '2-3': 'Q43595',\n",
       "  '3-0': 'Q750',\n",
       "  '3-1': 'Q2907',\n",
       "  '3-3': 'Q170688',\n",
       "  '4-0': 'Q155',\n",
       "  '4-1': 'Q119158',\n",
       "  '4-3': 'Q174',\n",
       "  '5-0': 'Q967',\n",
       "  '5-1': 'Q167551',\n",
       "  '5-3': 'Q3854',\n",
       "  '6-0': 'Q1009',\n",
       "  '6-1': 'Q3808',\n",
       "  '6-3': 'Q132830',\n",
       "  '7-0': 'Q16',\n",
       "  '7-1': 'Q1930',\n",
       "  '7-3': 'Q172',\n",
       "  '8-0': 'Q148',\n",
       "  '8-1': 'Q956',\n",
       "  '8-3': 'Q8686',\n",
       "  '9-0': 'Q1008',\n",
       "  '9-1': 'Q3768',\n",
       "  '9-3': 'Q1515',\n",
       "  '10-0': 'Q983',\n",
       "  '10-1': 'Q3818',\n",
       "  '10-3': 'Q320792',\n",
       "  '11-0': 'Q668',\n",
       "  '11-1': 'Q987',\n",
       "  '11-3': 'Q1156',\n",
       "  '12-0': 'Q232',\n",
       "  '12-1': 'Q1520',\n",
       "  '12-3': 'Q35493',\n",
       "  '13-0': 'Q347',\n",
       "  '13-1': 'Q1844',\n",
       "  '13-3': 'Q49657',\n",
       "  '14-0': 'Q233',\n",
       "  '14-1': 'Q23800',\n",
       "  '14-3': 'Q39583',\n",
       "  '15-0': 'Q702',\n",
       "  '15-1': 'Q42751',\n",
       "  '15-3': 'Q1009384',\n",
       "  '16-0': 'Q1028',\n",
       "  '16-1': 'Q3551',\n",
       "  '16-3': 'Q7903',\n",
       "  '17-0': 'Q836',\n",
       "  '17-1': 'Q37400',\n",
       "  '17-3': 'Q37995',\n",
       "  '18-0': 'Q664',\n",
       "  '18-1': 'Q23661',\n",
       "  '18-3': 'Q37100',\n",
       "  '19-0': 'Q1033',\n",
       "  '19-1': 'Q3787',\n",
       "  '19-3': 'Q8673',\n",
       "  '20-0': 'Q843',\n",
       "  '20-1': 'Q1362',\n",
       "  '20-3': 'Q8660',\n",
       "  '21-0': 'Q695',\n",
       "  '21-1': 'Q515229',\n",
       "  '21-3': 'Q189426',\n",
       "  '22-0': 'Q928',\n",
       "  '22-1': 'Q1461',\n",
       "  '22-3': 'Q1475',\n",
       "  '23-0': 'Q238',\n",
       "  '23-1': 'Q1848',\n",
       "  '23-3': 'Q185412',\n",
       "  '24-0': 'Q258',\n",
       "  '24-1': 'Q3926',\n",
       "  '24-3': 'Q34647',\n",
       "  '25-0': 'Q1049',\n",
       "  '25-1': 'Q1963',\n",
       "  '25-3': 'Q180921',\n",
       "  '26-0': 'Q854',\n",
       "  '26-1': 'Q41963',\n",
       "  '26-3': 'Q35381',\n",
       "  '27-0': 'Q39',\n",
       "  '27-1': 'Q70',\n",
       "  '27-3': 'Q72',\n",
       "  '28-0': 'Q924',\n",
       "  '28-1': 'Q3866',\n",
       "  '28-3': 'Q1960',\n",
       "  '29-0': 'Q754',\n",
       "  '29-1': 'Q39178',\n",
       "  '29-3': 'Q1444575',\n",
       "  '30-0': 'Q43',\n",
       "  '30-1': 'Q3640',\n",
       "  '30-3': 'Q406',\n",
       "  '31-0': 'Q878',\n",
       "  '31-1': 'Q1519',\n",
       "  '31-3': 'Q612',\n",
       "  '32-0': 'Q30',\n",
       "  '32-1': 'Q61',\n",
       "  '32-3': 'Q14435',\n",
       "  '33-0': 'Q881',\n",
       "  '33-1': 'Q1858',\n",
       "  '33-3': 'Q1854'},\n",
       " 'status': 'TODO'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
